Evaluating Vectorization Method: TF-IDF
Random Forest using TF-IDF: Accuracy = 0.9838

Random Forest_TF-IDF Results:
Accuracy: 0.9838
Precision: 0.9938
Recall: 0.9760
F1-Score: 0.9848
Confusion Matrix:
[[2232   16]
 [  63 2560]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.99      0.98      2248
           1       0.99      0.98      0.98      2623

    accuracy                           0.98      4871
   macro avg       0.98      0.98      0.98      4871
weighted avg       0.98      0.98      0.98      4871

Decision Tree using TF-IDF: Accuracy = 0.9733

Decision Tree_TF-IDF Results:
Accuracy: 0.9733
Precision: 0.9749
Recall: 0.9756
F1-Score: 0.9752
Confusion Matrix:
[[2182   66]
 [  64 2559]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      2248
           1       0.97      0.98      0.98      2623

    accuracy                           0.97      4871
   macro avg       0.97      0.97      0.97      4871
weighted avg       0.97      0.97      0.97      4871

Logistic Regression using TF-IDF: Accuracy = 0.9667

Logistic Regression_TF-IDF Results:
Accuracy: 0.9667
Precision: 0.9698
Recall: 0.9684
F1-Score: 0.9691
Confusion Matrix:
[[2169   79]
 [  83 2540]]
Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      2248
           1       0.97      0.97      0.97      2623

    accuracy                           0.97      4871
   macro avg       0.97      0.97      0.97      4871
weighted avg       0.97      0.97      0.97      4871

XGBoost using TF-IDF: Accuracy = 0.9838

XGBoost_TF-IDF Results:
Accuracy: 0.9838
Precision: 0.9923
Recall: 0.9775
F1-Score: 0.9848
Confusion Matrix:
[[2228   20]
 [  59 2564]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.99      0.98      2248
           1       0.99      0.98      0.98      2623

    accuracy                           0.98      4871
   macro avg       0.98      0.98      0.98      4871
weighted avg       0.98      0.98      0.98      4871

Gradient Boosting using TF-IDF: Accuracy = 0.9803

Gradient Boosting_TF-IDF Results:
Accuracy: 0.9803
Precision: 0.9903
Recall: 0.9729
F1-Score: 0.9815
Confusion Matrix:
[[2223   25]
 [  71 2552]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.99      0.98      2248
           1       0.99      0.97      0.98      2623

    accuracy                           0.98      4871
   macro avg       0.98      0.98      0.98      4871
weighted avg       0.98      0.98      0.98      4871

Evaluating Vectorization Method: CountVectorizer
Random Forest using CountVectorizer: Accuracy = 0.9836

Random Forest_CountVectorizer Results:
Accuracy: 0.9836
Precision: 0.9938
Recall: 0.9756
F1-Score: 0.9846
Confusion Matrix:
[[2232   16]
 [  64 2559]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.99      0.98      2248
           1       0.99      0.98      0.98      2623

    accuracy                           0.98      4871
   macro avg       0.98      0.98      0.98      4871
weighted avg       0.98      0.98      0.98      4871

Decision Tree using CountVectorizer: Accuracy = 0.9741

Decision Tree_CountVectorizer Results:
Accuracy: 0.9741
Precision: 0.9742
Recall: 0.9779
F1-Score: 0.9760
Confusion Matrix:
[[2180   68]
 [  58 2565]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      2248
           1       0.97      0.98      0.98      2623

    accuracy                           0.97      4871
   macro avg       0.97      0.97      0.97      4871
weighted avg       0.97      0.97      0.97      4871

Logistic Regression using CountVectorizer: Accuracy = 0.9762

Logistic Regression_CountVectorizer Results:
Accuracy: 0.9762
Precision: 0.9805
Recall: 0.9752
F1-Score: 0.9778
Confusion Matrix:
[[2197   51]
 [  65 2558]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.98      0.97      2248
           1       0.98      0.98      0.98      2623

    accuracy                           0.98      4871
   macro avg       0.98      0.98      0.98      4871
weighted avg       0.98      0.98      0.98      4871

XGBoost using CountVectorizer: Accuracy = 0.9852

XGBoost_CountVectorizer Results:
Accuracy: 0.9852
Precision: 0.9927
Recall: 0.9798
F1-Score: 0.9862
Confusion Matrix:
[[2229   19]
 [  53 2570]]
Classification Report:
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      2248
           1       0.99      0.98      0.99      2623

    accuracy                           0.99      4871
   macro avg       0.98      0.99      0.99      4871
weighted avg       0.99      0.99      0.99      4871

Gradient Boosting using CountVectorizer: Accuracy = 0.9803

Gradient Boosting_CountVectorizer Results:
Accuracy: 0.9803
Precision: 0.9914
Recall: 0.9718
F1-Score: 0.9815
Confusion Matrix:
[[2226   22]
 [  74 2549]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.99      0.98      2248
           1       0.99      0.97      0.98      2623

    accuracy                           0.98      4871
   macro avg       0.98      0.98      0.98      4871
weighted avg       0.98      0.98      0.98      4871

Evaluating Vectorization Method: Word2Vec
Random Forest using Word2Vec: Accuracy = 0.9499

Random Forest_Word2Vec Results:
Accuracy: 0.9499
Precision: 0.9514
Recall: 0.9558
F1-Score: 0.9536
Confusion Matrix:
[[2120  128]
 [ 116 2507]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.94      0.95      2248
           1       0.95      0.96      0.95      2623

    accuracy                           0.95      4871
   macro avg       0.95      0.95      0.95      4871
weighted avg       0.95      0.95      0.95      4871

Decision Tree using Word2Vec: Accuracy = 0.8924

Decision Tree_Word2Vec Results:
Accuracy: 0.8924
Precision: 0.8980
Recall: 0.9028
F1-Score: 0.9004
Confusion Matrix:
[[1979  269]
 [ 255 2368]]
Classification Report:
              precision    recall  f1-score   support

           0       0.89      0.88      0.88      2248
           1       0.90      0.90      0.90      2623

    accuracy                           0.89      4871
   macro avg       0.89      0.89      0.89      4871
weighted avg       0.89      0.89      0.89      4871

Logistic Regression using Word2Vec: Accuracy = 0.9645

Logistic Regression_Word2Vec Results:
Accuracy: 0.9645
Precision: 0.9697
Recall: 0.9642
F1-Score: 0.9669
Confusion Matrix:
[[2169   79]
 [  94 2529]]
Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      2248
           1       0.97      0.96      0.97      2623

    accuracy                           0.96      4871
   macro avg       0.96      0.96      0.96      4871
weighted avg       0.96      0.96      0.96      4871

XGBoost using Word2Vec: Accuracy = 0.9633

XGBoost_Word2Vec Results:
Accuracy: 0.9633
Precision: 0.9693
Recall: 0.9623
F1-Score: 0.9658
Confusion Matrix:
[[2168   80]
 [  99 2524]]
Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      2248
           1       0.97      0.96      0.97      2623

    accuracy                           0.96      4871
   macro avg       0.96      0.96      0.96      4871
weighted avg       0.96      0.96      0.96      4871

Gradient Boosting using Word2Vec: Accuracy = 0.9555

Gradient Boosting_Word2Vec Results:
Accuracy: 0.9555
Precision: 0.9567
Recall: 0.9607
F1-Score: 0.9587
Confusion Matrix:
[[2134  114]
 [ 103 2520]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.95      0.95      2248
           1       0.96      0.96      0.96      2623

    accuracy                           0.96      4871
   macro avg       0.96      0.96      0.96      4871
weighted avg       0.96      0.96      0.96      4871

Evaluating Vectorization Method: FastText
Random Forest using FastText: Accuracy = 0.9476

Random Forest_FastText Results:
Accuracy: 0.9476
Precision: 0.9488
Recall: 0.9543
F1-Score: 0.9515
Confusion Matrix:
[[2113  135]
 [ 120 2503]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.94      0.94      2248
           1       0.95      0.95      0.95      2623

    accuracy                           0.95      4871
   macro avg       0.95      0.95      0.95      4871
weighted avg       0.95      0.95      0.95      4871

Decision Tree using FastText: Accuracy = 0.8998

Decision Tree_FastText Results:
Accuracy: 0.8998
Precision: 0.9067
Recall: 0.9074
F1-Score: 0.9070
Confusion Matrix:
[[2003  245]
 [ 243 2380]]
Classification Report:
              precision    recall  f1-score   support

           0       0.89      0.89      0.89      2248
           1       0.91      0.91      0.91      2623

    accuracy                           0.90      4871
   macro avg       0.90      0.90      0.90      4871
weighted avg       0.90      0.90      0.90      4871

Logistic Regression using FastText: Accuracy = 0.9633

Logistic Regression_FastText Results:
Accuracy: 0.9633
Precision: 0.9675
Recall: 0.9642
F1-Score: 0.9658
Confusion Matrix:
[[2163   85]
 [  94 2529]]
Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      2248
           1       0.97      0.96      0.97      2623

    accuracy                           0.96      4871
   macro avg       0.96      0.96      0.96      4871
weighted avg       0.96      0.96      0.96      4871

XGBoost using FastText: Accuracy = 0.9618

XGBoost_FastText Results:
Accuracy: 0.9618
Precision: 0.9667
Recall: 0.9623
F1-Score: 0.9645
Confusion Matrix:
[[2161   87]
 [  99 2524]]
Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.96      0.96      2248
           1       0.97      0.96      0.96      2623

    accuracy                           0.96      4871
   macro avg       0.96      0.96      0.96      4871
weighted avg       0.96      0.96      0.96      4871

Gradient Boosting using FastText: Accuracy = 0.9546

Gradient Boosting_FastText Results:
Accuracy: 0.9546
Precision: 0.9584
Recall: 0.9573
F1-Score: 0.9578
Confusion Matrix:
[[2139  109]
 [ 112 2511]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.95      0.95      2248
           1       0.96      0.96      0.96      2623

    accuracy                           0.95      4871
   macro avg       0.95      0.95      0.95      4871
weighted avg       0.95      0.95      0.95      4871

Evaluating Vectorization Method: Doc2Vec
Random Forest using Doc2Vec: Accuracy = 0.9446

Random Forest_Doc2Vec Results:
Accuracy: 0.9446
Precision: 0.9405
Recall: 0.9577
F1-Score: 0.9490
Confusion Matrix:
[[2089  159]
 [ 111 2512]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94      2248
           1       0.94      0.96      0.95      2623

    accuracy                           0.94      4871
   macro avg       0.95      0.94      0.94      4871
weighted avg       0.94      0.94      0.94      4871

Decision Tree using Doc2Vec: Accuracy = 0.8058

Decision Tree_Doc2Vec Results:
Accuracy: 0.8058
Precision: 0.8185
Recall: 0.8216
F1-Score: 0.8200
Confusion Matrix:
[[1770  478]
 [ 468 2155]]
Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.79      0.79      2248
           1       0.82      0.82      0.82      2623

    accuracy                           0.81      4871
   macro avg       0.80      0.80      0.80      4871
weighted avg       0.81      0.81      0.81      4871

Logistic Regression using Doc2Vec: Accuracy = 0.9524

Logistic Regression_Doc2Vec Results:
Accuracy: 0.9524
Precision: 0.9534
Recall: 0.9584
F1-Score: 0.9559
Confusion Matrix:
[[2125  123]
 [ 109 2514]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.95      0.95      2248
           1       0.95      0.96      0.96      2623

    accuracy                           0.95      4871
   macro avg       0.95      0.95      0.95      4871
weighted avg       0.95      0.95      0.95      4871

XGBoost using Doc2Vec: Accuracy = 0.9532

XGBoost_Doc2Vec Results:
Accuracy: 0.9532
Precision: 0.9548
Recall: 0.9584
F1-Score: 0.9566
Confusion Matrix:
[[2129  119]
 [ 109 2514]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.95      0.95      2248
           1       0.95      0.96      0.96      2623

    accuracy                           0.95      4871
   macro avg       0.95      0.95      0.95      4871
weighted avg       0.95      0.95      0.95      4871

Gradient Boosting using Doc2Vec: Accuracy = 0.9450

Gradient Boosting_Doc2Vec Results:
Accuracy: 0.9450
Precision: 0.9412
Recall: 0.9577
F1-Score: 0.9494
Confusion Matrix:
[[2091  157]
 [ 111 2512]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94      2248
           1       0.94      0.96      0.95      2623

    accuracy                           0.94      4871
   macro avg       0.95      0.94      0.94      4871
weighted avg       0.95      0.94      0.94      4871

Evaluating Vectorization Method: BERT
Random Forest using BERT: Accuracy = 0.9472

Random Forest_BERT Results:
Accuracy: 0.9472
Precision: 0.9571
Recall: 0.9443
F1-Score: 0.9507
Confusion Matrix:
[[2137  111]
 [ 146 2477]]
Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.95      0.94      2248
           1       0.96      0.94      0.95      2623

    accuracy                           0.95      4871
   macro avg       0.95      0.95      0.95      4871
weighted avg       0.95      0.95      0.95      4871

Decision Tree using BERT: Accuracy = 0.8815

Decision Tree_BERT Results:
Accuracy: 0.8815
Precision: 0.8878
Recall: 0.8929
F1-Score: 0.8903
Confusion Matrix:
[[1952  296]
 [ 281 2342]]
Classification Report:
              precision    recall  f1-score   support

           0       0.87      0.87      0.87      2248
           1       0.89      0.89      0.89      2623

    accuracy                           0.88      4871
   macro avg       0.88      0.88      0.88      4871
weighted avg       0.88      0.88      0.88      4871

Logistic Regression using BERT: Accuracy = 0.9737

Logistic Regression_BERT Results:
Accuracy: 0.9737
Precision: 0.9771
Recall: 0.9741
F1-Score: 0.9756
Confusion Matrix:
[[2188   60]
 [  68 2555]]
Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.97      0.97      2248
           1       0.98      0.97      0.98      2623

    accuracy                           0.97      4871
   macro avg       0.97      0.97      0.97      4871
weighted avg       0.97      0.97      0.97      4871

XGBoost using BERT: Accuracy = 0.9672

XGBoost_BERT Results:
Accuracy: 0.9672
Precision: 0.9764
Recall: 0.9623
F1-Score: 0.9693
Confusion Matrix:
[[2187   61]
 [  99 2524]]
Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.97      0.96      2248
           1       0.98      0.96      0.97      2623

    accuracy                           0.97      4871
   macro avg       0.97      0.97      0.97      4871
weighted avg       0.97      0.97      0.97      4871

Gradient Boosting using BERT: Accuracy = 0.9594

Gradient Boosting_BERT Results:
Accuracy: 0.9594
Precision: 0.9662
Recall: 0.9581
F1-Score: 0.9621
Confusion Matrix:
[[2160   88]
 [ 110 2513]]
Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.96      0.96      2248
           1       0.97      0.96      0.96      2623

    accuracy                           0.96      4871
   macro avg       0.96      0.96      0.96      4871
weighted avg       0.96      0.96      0.96      4871
